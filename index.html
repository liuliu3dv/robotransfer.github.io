<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="RoboTransfer: Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer">
  <meta name="keywords" content="Robotic, Video Generation, Imitation Learning, Data Augmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RoboTransfer: Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL'); -->
  <!-- </script> -->
  <style>
    .hr {width: 100%; height: 1px; margin: 48px 0; background-color: #d6dbdf;}
    </style>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <!-- <h1 class="title is-1 publication-title">RoboTransfer: Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer</h1> -->
         
          <div style="display: flex; align-items: center; max-width: 100%; gap: 4px;">
            <img src="./static/images/method/pin.png" alt="Logo" style="height: 2.4cm;">
            <h1 class="title is-1 publication-title" style="margin: 0; flex: 1; min-width: 0;">
              <p>RoboTransfer</p>
              Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer
            </h1>
          </div>

          <div class="is-size-5 publication-authors">
              <p><span class="author-block">
                   <a href="https://liuliu3dv.github.io">Liu Liu</a><sup>1</sup>,</span>
              <span class="author-block">
                  Xiaofeng Wang</a><sup>2</sup>,</span>
              <span class="author-block">
                  Guosheng Zhao<sup>2,3</sup>,</span>
              <span class="author-block">
                  Keyu Li<sup>1</sup>,</span>
              <span class="author-block">
                  Wenkang Qin<sup>2</sup>,</span></p>
              <span class="author-block">
                  Jiaxiong Qiu<sup>1</sup>,</span>
              <span class="author-block">
                  Zheng Zhu<sup>2</sup>,</span>
              <span class="author-block">
                  Guan Huang<sup>2</sup>,</span>
              <span class="author-block">
                  Zhizhong Su<sup>1</sup>
              </span>
          </div>
      
          <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Horizon Robotics,</span>
              <span class="author-block"><sup>2</sup>GigaAI,</span>
              <span class="author-block"><sup>3</sup>CASIA</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a 
                href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=IJbSffTzAsE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Dataset Link.
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video section -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">RoboTransfer Video</h2>
        <div class="publication-video" style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
          <iframe 
            src="https://www.youtube.com/embed/IJbSffTzAsE?rel=0&modestbranding=1" 
            frameborder="0" 
            allow="autoplay; encrypted-media" 
            allowfullscreen 
            style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
          </iframe>
        </div>
      </div>
    </div>

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- Framework Image -->

          <p>
            Imitation Learning has become a fundamental approach in robotic manipulation. 
            However, collecting large-scale real-world robot demonstrations is prohibitively expensive. 
            Simulators offer a cost-effective alternative, but the sim-to-real gap make it extremely 
            challenging to scale. 
          </p>
          <p>
            Therefore, we introduce RoboTransfer, a diffusion-based video generation framework for robotic data synthesis. 
            Unlike previous methods, RoboTransfer integrates multi-view geometry with explicit control over scene components, 
            such as background and object attributes. 
            By incorporating cross-view feature interactions and global depth/normal conditions,
            RoboTransfer ensures geometry consistency across views. 
            This framework allows fine-grained control, including background edits and object swaps. 
          </p> 
          
          <img src="./static/images/method/robotransfer.png" alt="Framework Diagram" style="max-width: 100%; height: auto; margin-bottom: 20px;">

          <p>
            Experiments demonstrate that RoboTransfer is capable of generating multi-view videos with enhanced 
            geometric consistency and visual fidelity. Moreover, policies trained on data generated by RoboTransfer 
            achieve a 33.3% relative improvement in success rate under the Diff-Obj setting, 
            and a substantial 251% relative improvement under the more challenging Diff-All scenario.
          </p>
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method Section -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          
          <h3 class="title is-4">Model</h3>
          <img src="./static/images/method/model.png" alt="Framework Diagram" style="max-width: 100%; height: auto; margin-bottom: 20px;">
          <p>
            To ensure multi-view consistency
            during generation, we perform multi-view consistent modeling, enabling the generation process to
            reason jointly over information from different viewpoints. On the conditions side, RoboTransfer in-
            corporates fine-grained control by encoding both geometric and appearance information. Specifically,
            we represent geometry using scaled depth maps and surface normal maps, capturing the underlying
            3D structure of the scene. Meanwhile, the appearance is encoded using reference background images
            and object-specific images, providing detailed control over texture, color, and contextual appearance.
            In the following sections, we first introduce the multi-view consistent modeling, and then describe
            the encoding mechanisms for geometric and appearance conditions, respectively.
          </p>

          <h3 class="title is-4">Dataset Construction</h3>
          <img src="./static/images/method/data_construct.png" alt="Framework Diagram" style="max-width: 100%; height: auto; margin-bottom: 20px;">
          <p>
            The data processing pipeline consists of two
            main components: Geometry conditions (left) are derived by using Mono-Normal and Video Depth
            Anything, which are scale-aligned with sensor depth to ensure consistency. Appearance conditions
            (right) are obtained by sampling keyframes from the video. GPT-4 is used to generate object
            descriptions, which are then processed by Grounding-SAM to create per-object masks. Additionally,
            background inpainting is used to generate complete reference backgrounds.          
          </p>

        </div>
      </div>
    </div>
  </div>
</section>


<!-- Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Qualitative Results</h2>
        <div class="content has-text-justified">

          <!-- Real2Real -->
          <h3 class="title is-4">1. Real2Real</h3>
          <p>Placeholder for Real2Real result description.</p>
          <figure class="image is-16by9">
            <video controls muted loop>
              <source src="PATH/TO/real2real.mp4" type="video/mp4">
            </video>
          </figure>

          <!-- Sim2Real -->
          <h3 class="title is-4">2. Sim2Real</h3>
          <p>Placeholder for Sim2Real result description.</p>
          <figure class="image is-16by9">
            <video controls muted loop>
              <source src="PATH/TO/sim2real.mp4" type="video/mp4">
            </video>
          </figure>

          <!-- Compare -->
          <h3 class="title is-4">3. Compare</h3>
          <p>Placeholder for comparison results between methods.</p>
          <figure class="image">
            <img src="PATH/TO/compare.png" alt="Comparison Image">
          </figure>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- Experiments Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiments</h2>
        <div class="content has-text-justified">

          <!-- Synthesis Quality -->
          <h3 class="title is-4">1. Synthesis Quality</h3>
          <p>Placeholder for synthesis quality evaluation and metrics.</p>
          <figure class="image">
            <img src="PATH/TO/synthesis-quality.png" alt="Synthesis Quality">
          </figure>

          <!-- Real Robot Experiments -->
          <h3 class="title is-4">2. Real Robot Experiments</h3>
          <p>Placeholder for real-world robot deployment experiments and success rates.</p>
          <figure class="image is-16by9">
            <video controls muted loop>
              <source src="PATH/TO/real-robot.mp4" type="video/mp4">
            </video>
          </figure>

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
